{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read sentiment and modifier dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May  6 21:12:32 2020\n",
    "\n",
    "@author: dell\n",
    "\"\"\"\n",
    "\n",
    "#载入情感词典\n",
    "# 打开词典文件，返回列表\n",
    "import pandas as pd\n",
    "import json\n",
    "def open_dict(Dict='hahah',path='data/'):\n",
    "    path = path + '%s.txt' %Dict\n",
    "    dictionary = open(path, 'r', encoding='utf-8-sig',errors='ignore')#encoding='utf-8-sig',检查是否有文件头，并去掉\n",
    "    dict = []\n",
    "    for word in dictionary:\n",
    "        word=word.strip('\\n')\n",
    "        word=word.strip(' ')\n",
    "        dict.append(word)\n",
    "    return dict\n",
    "posdict = open_dict(Dict='sentiment_dict/posdict')#积极情感词典\n",
    "negdict = open_dict(Dict='sentiment_dict/negdict')#消极情感词典\n",
    "inversedict=open_dict(Dict='modifier_dict/inversedict')\n",
    "mostdict = open_dict(Dict='modifier_dict/mostdict')\n",
    "verydict= open_dict(Dict='modifier_dict/verydict')\n",
    "moredict = open_dict(Dict='modifier_dict/moredict')\n",
    "ishdict = open_dict(Dict='modifier_dict/ishdict')\n",
    "insufficientdict = open_dict(Dict='modifier_dict/insufficientdict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add Hotel related sentiment words to the sentiment dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('data/sentiment_dict/酒店情感词典.txt','r',encoding='utf-8')\n",
    "words = []\n",
    "value=[]\n",
    "for word in f.readlines():\n",
    "    words.append(word.split(' ')[0])\n",
    "    value.append(float(word.split(' ')[1].strip('\\n')))\n",
    "    \n",
    "c={'words':words,\n",
    "   'value':value}\n",
    "fd=pd.DataFrame(c)\n",
    "pos=fd['words'][fd.value>0]\n",
    "posdict=posdict+list(pos)    ##加入酒店相关的正向情感词\n",
    "neg=fd['words'][fd.value<0]\n",
    "negdict=negdict+list(neg)    ##加入酒店相关的负向情感词\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist=['环境', '卫生', '周边环境', '周围环境', '装修', '隔音', '卫生条件', '通风', '光线', '采光', '视野', '风景', '景观', '海景' ,'景色']\n",
    "blist=['服务', '态度', '服务态度', '服务质量', '办事效率', '工作人员', '服务员', '服务生', '客服', '阿姨' ,'员工', '经理', '前台', '店家', '素质', '保洁', '接待', '打扫', '收拾', '整理']\n",
    "clist=['设施', '配置', '家电', '设备', '物品', '家具', '用品', '生活用品', '基础设施', '用具', '装饰']\n",
    "dlist=['价格', '价钱', '价位', '房价', '性价比', '费用', '房费']\n",
    "elist=['交通', '位置', '地理', '地点', '地理位置', '地段', '周边', '周围', '附近', '出行', '公交', '公交车', '公交站', '公交车站', '地铁', '商业区', '市中心']\n",
    "flist=['整体', '总体', '总的来说', '总之', '酒店', '公寓', '宾馆']\n",
    "\n",
    "t_list=alist+blist+clist+dlist+elist+flist\n",
    "\n",
    "q_list=posdict+negdict\n",
    "\n",
    "x_list=inversedict+mostdict+verydict+moredict+ishdict+insufficientdict\n",
    "\n",
    "q_list1=['便宜','划算','实惠','贵','优惠','不贵','物超所值','经济','涨价']#价格\n",
    "q_list2=['方便','便利','便捷']#交通\n",
    "q_list3=['卫生','干净','整洁','脏','舒适','舒服','潮湿','温馨','明亮','宽敞','干净利落','潮','暗','昏暗','漏水','反味','难闻','发霉']#环境\n",
    "q_list4=['齐全','旧','陈旧','新','老旧','破旧','很全']#设施\n",
    "q_list5=['热情','贴心','耐心','友善','冷漠','体贴','周到','亲切','细心','细致','和蔼']#服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyltp\n",
      "  Downloading pyltp-0.4.0-cp37-cp37m-macosx_10_9_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyltp\n",
      "Successfully installed pyltp-0.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/Users/dizhou/anaconda3/envs/zhihu_debug/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install pyltp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "try:\n",
    "    imp.find_module('ltp')\n",
    "    found = True\n",
    "except ImportError:\n",
    "    found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /Users/dizhou/anaconda3\n",
      "nytbook                  /Users/dizhou/anaconda3/envs/nytbook\n",
      "zhihu_debug              /Users/dizhou/anaconda3/envs/zhihu_debug\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-faf68f5095a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mltp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLTP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ltp'"
     ]
    }
   ],
   "source": [
    "from ltp import LTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#句法分析\n",
    "from pyltp import Parser#导入库Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyltp import Segmentor #导入Segmentor库\n",
    "from pyltp import Postagger #导入Postagger库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_detail(sentence):\n",
    "    math_path = r\"C:\\Users\\dell\\Desktop\\py_anaconda\\LTP_model\\cws.model\"#LTP分词模型库\n",
    "    segmentor = Segmentor()#实例化分词模块\n",
    "    segmentor.load(math_path)#加载分词库\n",
    "    words = segmentor.segment(sentence)\n",
    "    words=' '.join(words).split()\n",
    "\n",
    "    math_path1 = r\"C:\\Users\\dell\\Desktop\\py_anaconda\\LTP_model\\pos.model\"#LTP词性标注模型库\n",
    "    postagger = Postagger() #实例化词性模块\n",
    "    postagger.load(math_path1)#加载词性库\n",
    "    postags = postagger.postag(words)#这里的words是分词后的结果\n",
    "    postags=' '.join(postags).split()#分割标注后的结果\n",
    "    \n",
    "    math_path2 = r\"C:\\Users\\dell\\Desktop\\py_anaconda\\LTP_model\\parser.model\"#LTP依存分析模型库\n",
    "    parser = Parser() # 初始化实例\n",
    "    parser.load(math_path2)#加载依存分析库\n",
    "    arcs = parser.parse(words,postags)    \n",
    "    head=[]\n",
    "    relation=[]\n",
    "    for arc in arcs:\n",
    "        head.append(arc.head)\n",
    "        relation.append(arc.relation)\n",
    "    return head,relation,words,postags\n",
    "    del head,relation,words,postags\n",
    "\n",
    "\n",
    "def xiushi(word,words,relation,head):#找到情感词的修饰词\n",
    "    j=0\n",
    "    a=[]\n",
    "    for i in words:\n",
    "        if i in x_list and relation[j] in ['CMP','ADV'] and words[head[j]-1]==word:\n",
    "            a.append(i)\n",
    "        j+=1\n",
    "    return a\n",
    "                \n",
    "\n",
    "\n",
    "#例子：服务很不好\n",
    "    #非常宽敞 特别干净 面积真的很大 装修风格很简单但真的很好看 挺商务的 最近住过的大连酒店这里最喜欢了 住过港汇好多次了哈哈\n",
    "    #性价比很高的酒店，住着很舒服，服务人员也都非常热情，周边交通也很方便\n",
    "\n",
    "\n",
    "def get_list(sentence):\n",
    "    i=0\n",
    "    d_list=[]    \n",
    "    head,relation,words,postags=get_detail(sentence)\n",
    "\n",
    "    for word in words:\n",
    "        if word in t_list and relation[i] in ['SBV','VOB','FOB'] and words[head[i]-1] in q_list:\n",
    "            d={'属性词':word,'情感词':words[head[i]-1],'修饰词':xiushi(words[head[i]-1],words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word in q_list and relation[i] in ['ATT','CMP'] and words[head[i]-1] in t_list:\n",
    "            d={'属性词':words[head[i]-1],'情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word in t_list and relation[i] in ['COO'] and words[head[i]-1] in q_list:\n",
    "            d={'属性词':word,'情感词':words[head[i]-1],'修饰词':xiushi(words[head[i]-1],words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word in q_list and relation[i] in ['COO'] and words[head[i]-1] in t_list:\n",
    "            d={'属性词':words[head[i]-1],'情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        i+=1\n",
    "    \n",
    "    ##潜在属性词抽取\n",
    "    q_word=[]#抽取过的情感词集和\n",
    "    for d in d_list:\n",
    "        q_word.append(d['情感词'])\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in q_word and word in q_list1:\n",
    "            d={'属性词':'价格','情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word not in q_word and word in q_list2:\n",
    "            d={'属性词':'交通','情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word not in q_word and word in q_list3:\n",
    "            d={'属性词':'环境','情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word not in q_word and word in q_list4:\n",
    "            d={'属性词':'设施','情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "        if word not in q_word and word in q_list5:\n",
    "            d={'属性词':'服务','情感词':word,'修饰词':xiushi(word,words,relation,head)}\n",
    "            d_list.append(d)\n",
    "    return(d_list)\n",
    "    del d_list,head,relation,words,postags,q_word\n",
    "\n",
    "\n",
    "\n",
    "#倾向分析\n",
    "#定义判断奇偶的函数\n",
    "def judgeodd(num):\n",
    "    if num%2==0:\n",
    "        return 'even'\n",
    "    else:\n",
    "        return 'odd'\n",
    "\n",
    "def score(alist,d_list):\n",
    "    totalcount=0\n",
    "    a=0\n",
    "    for d in d_list:\n",
    "        count=0\n",
    "        if d['属性词'] in alist:\n",
    "            a+=1\n",
    "            if d['情感词'] in posdict:\n",
    "                c = 0 #情感词前否定词的个数\n",
    "                for w in d['修饰词']:\n",
    "                    if w in inversedict:\n",
    "                        c += 1 \n",
    "                if judgeodd(c) == 'odd':\n",
    "                    count=-1\n",
    "                else:\n",
    "                    count=1\n",
    "            else:\n",
    "                c=0\n",
    "                for w in d['修饰词']:\n",
    "                    if w in inversedict:\n",
    "                        c += 1 \n",
    "                if judgeodd(c) == 'odd':\n",
    "                    count=1\n",
    "                else:\n",
    "                    count=-1\n",
    "        totalcount+=count\n",
    "    if a==0:\n",
    "        return 20\n",
    "    else:\n",
    "        return totalcount\n",
    "    del d_list,totalcount\n",
    "\n",
    "\n",
    "def s_sentence(d_list):\n",
    "    score_dict={'环境':20,\n",
    "                '服务':20,\n",
    "                '设施':20,\n",
    "                '价格':20,\n",
    "                '交通':20,\n",
    "                '整体':20,} \n",
    "    totalcount1=score(alist,d_list)#环境\n",
    "    if totalcount1==20:\n",
    "        score_dict['环境']=0##表示没有相关评论\n",
    "    elif totalcount1>0:\n",
    "        score_dict['环境']=1\n",
    "    elif totalcount1<=0:\n",
    "        score_dict['环境']=-1\n",
    "        \n",
    "    totalcount2=score(blist,d_list)#服务\n",
    "    if totalcount2==20:\n",
    "        score_dict['服务']=0##表示没有相关评论\n",
    "    elif totalcount2>0:\n",
    "        score_dict['服务']=1\n",
    "    elif totalcount2<=0:\n",
    "        score_dict['服务']=-1    \n",
    "    \n",
    "    totalcount3=score(clist,d_list)#设施\n",
    "    if totalcount3==20:\n",
    "        score_dict['设施']=0##表示没有相关评论\n",
    "    elif totalcount3>0:\n",
    "        score_dict['设施']=1\n",
    "    elif totalcount3<=0:\n",
    "        score_dict['设施']=-1    \n",
    "\n",
    "    totalcount4=score(dlist,d_list)#价格\n",
    "    if totalcount4==20:\n",
    "        score_dict['价格']=0##表示没有相关评论\n",
    "    elif totalcount4>0:\n",
    "        score_dict['价格']=1\n",
    "    elif totalcount4<=0:\n",
    "        score_dict['价格']=-1    \n",
    "\n",
    "    totalcount5=score(elist,d_list)#交通\n",
    "    if totalcount5==20:\n",
    "        score_dict['交通']=0##表示没有相关评论\n",
    "    elif totalcount5>0:\n",
    "        score_dict['交通']=1\n",
    "    elif totalcount5<=0:\n",
    "        score_dict['交通']=-1    \n",
    "\n",
    "    totalcount6=score(flist,d_list)#整体\n",
    "    if totalcount6==20:\n",
    "        score_dict['整体']=0##表示没有相关评论\n",
    "    elif totalcount6>0:\n",
    "        score_dict['整体']=1\n",
    "    elif totalcount6<=0:\n",
    "        score_dict['整体']=-1    \n",
    "       \n",
    "    return score_dict\n",
    "    del score_dict,totalcount1,totalcount2,totalcount3,totalcount4,totalcount5,totalcount6\n",
    "    \n",
    "\n",
    "\n",
    "#抽取出词对\n",
    "import gc\n",
    "content=[]\n",
    "score_list=[]\n",
    "with open(r'C:\\Users\\dell\\Desktop\\论文\\newdata\\如家酒店(大连星海公园店)(共357条).json','r', encoding='utf-8') as fp:\n",
    "    con=json.load(fp)\n",
    "    for i in range(0,len(con)):\n",
    "        content.append(con[i]['content'].replace(' ','').replace('\\n', '').replace('\\r', ''))\n",
    "\n",
    "for sentence in content[0:50]:\n",
    "    d_list=get_list(sentence)\n",
    "    score_dict=s_sentence(d_list)\n",
    "    score_list.append(score_dict)\n",
    "    del score_dict,d_list\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "fo = open('C:/Users/dell/Desktop/论文/newdata/score.json', 'r', encoding='utf-8')\n",
    "#json.dump(score_list[0:10],fo,ensure_ascii=False, indent=4, sort_keys=False)\n",
    "#fo.write(score_list)\n",
    "con=json.load(fo)\n",
    "con.append(score_list)\n",
    "json.dump(con,fo,ensure_ascii=False, indent=4, sort_keys=False)\n",
    "fo.close()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
